{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_1 = pd.read_csv('cat_1.csv', sep=';',encoding='windows-1251')\n",
    "categ_2 = pd.read_csv('cat_2.csv', sep=';',encoding='windows-1251')\n",
    "categ_3 = pd.read_csv('cat_3.csv', sep=';',encoding='windows-1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "categs_combined = pd.concat([categ_1,categ_2,categ_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "categs_combined['aut'] = categs_combined['aut'].fillna('Неизвестен')\n",
    "categs_combined['title'] = categs_combined['title'].fillna('Неизестно')\n",
    "categs_combined['place'] = categs_combined['place'].fillna('Неизестно')\n",
    "categs_combined['publ'] = categs_combined['publ'].fillna('Неизвестен')\n",
    "categs_combined['yea'] = categs_combined['yea'].fillna('Неизвестен')\n",
    "categs_combined['lan'] = categs_combined['lan'].fillna('Неизвестен')\n",
    "categs_combined['rubrics'] = categs_combined['rubrics'].fillna('Неизвестны')\n",
    "categs_combined['person'] = categs_combined['person'].fillna('Неизвестен')\n",
    "categs_combined['serial'] = categs_combined['serial'].fillna('Неизвестен')\n",
    "categs_combined['ager'] = categs_combined['ager'].fillna('Неизвестен')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-anime",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_1 = pd.read_csv('fund_1.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_2 = pd.read_csv('fund_2.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_3 = pd.read_csv('fund_3.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_4 = pd.read_csv('fund_4.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_5 = pd.read_csv('fund_5.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_6 = pd.read_csv('fund_6.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_7 = pd.read_csv('fund_7.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_8 = pd.read_csv('fund_8.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_9 = pd.read_csv('fund_9.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_10 = pd.read_csv('fund_10_fix.csv', sep=';',encoding='windows-1251')\n",
    "fund_10 = fund_10.drop(['Unnamed: 8','Unnamed: 9'],axis=1)\n",
    "\n",
    "fund_11 = pd.read_csv('fund_11_fix.csv', sep=';',encoding='windows-1251')\n",
    "fund_11 = fund_11.drop(['Unnamed: 8','Unnamed: 9'],axis=1)\n",
    "\n",
    "fund_12 = pd.read_csv('fund_12_fix.csv', sep=';',encoding='windows-1251')\n",
    "fund_12 = fund_12.drop(['Unnamed: 8','Unnamed: 9'],axis=1)\n",
    "\n",
    "fund_13 = pd.read_csv('fund_13_fix.csv', sep=';',encoding='windows-1251')\n",
    "fund_13 = fund_13.drop(['Unnamed: 8','Unnamed: 9'],axis=1)\n",
    "\n",
    "fund_14 = pd.read_csv('fund_14.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_15 = pd.read_csv('fund_15.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_16 = pd.read_csv('fund_16.csv', sep=';',encoding='windows-1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "funds_combined = pd.concat(\n",
    "    [fund_1,\n",
    "     fund_2,\n",
    "     fund_3,\n",
    "     fund_4,\n",
    "     fund_5,\n",
    "     fund_6,\n",
    "     fund_7,\n",
    "     fund_8,\n",
    "     fund_9,\n",
    "     fund_10,\n",
    "     fund_11,\n",
    "     fund_12,\n",
    "     fund_13,\n",
    "     fund_14,\n",
    "     fund_15,\n",
    "     fund_16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "funds_combined = funds_combined.rename(columns={'Unnamed: 6':'siglaID_2',\n",
    "                               'Unnamed: 7':'inventoryNumber_2', \n",
    "                               'Unnamed: 8':'barCode_2',\n",
    "                               'Unnamed: 9':'trackIndex_2'})\n",
    "\n",
    "funds_combined['trackIndex'] = funds_combined['trackIndex'].fillna('Неизвестен')\n",
    "funds_combined['siglaID_2'] = funds_combined['siglaID_2'].fillna('Нет')\n",
    "funds_combined['inventoryNumber_2'] = funds_combined['inventoryNumber_2'].fillna('Нет')\n",
    "#funds_combined['barCode_2'] = funds_combined['barCode_2'].fillna('Нет')\n",
    "#funds_combined['trackIndex_2'] = funds_combined['trackIndex_2'].fillna('Нет')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "circ_1 = pd.read_csv('circulaton_1.csv', sep=';',encoding='windows-1251')\n",
    "circ_2 = pd.read_csv('circulaton_2.csv', sep=';',encoding='windows-1251')\n",
    "circ_3 = pd.read_csv('circulaton_3.csv', sep=';',encoding='windows-1251')\n",
    "circ_4 = pd.read_csv('circulaton_4.csv', sep=';',encoding='windows-1251')\n",
    "circ_5 = pd.read_csv('circulaton_5.csv', sep=';',encoding='windows-1251')\n",
    "circ_6 = pd.read_csv('circulaton_6.csv', sep=';',encoding='windows-1251')\n",
    "circ_7 = pd.read_csv('circulaton_7.csv', sep=';',encoding='windows-1251')\n",
    "circ_8 = pd.read_csv('circulaton_8.csv', sep=';',encoding='windows-1251')\n",
    "circ_9 = pd.read_csv('circulaton_9.csv', sep=';',encoding='windows-1251')\n",
    "circ_10 = pd.read_csv('circulaton_10.csv', sep=';',encoding='windows-1251')\n",
    "circ_11 = pd.read_csv('circulaton_11.csv', sep=';',encoding='windows-1251')\n",
    "circ_12 = pd.read_csv('circulaton_12.csv', sep=';',encoding='windows-1251')\n",
    "circ_13 = pd.read_csv('circulaton_13.csv', sep=';',encoding='windows-1251')\n",
    "circ_14 = pd.read_csv('circulaton_14.csv', sep=';',encoding='windows-1251')\n",
    "circ_15 = pd.read_csv('circulaton_15.csv', sep=';',encoding='windows-1251')\n",
    "circ_16 = pd.read_csv('circulaton_16.csv', sep=';',encoding='windows-1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "circs_combined = pd.concat(\n",
    "    [circ_1,\n",
    "     circ_2,\n",
    "     circ_3,\n",
    "     circ_4,\n",
    "     circ_5,\n",
    "     circ_6,\n",
    "     circ_7,\n",
    "     circ_8,\n",
    "     circ_9,\n",
    "     circ_10,\n",
    "     circ_11,\n",
    "     circ_12,\n",
    "     circ_13,\n",
    "     circ_14,\n",
    "     circ_15,\n",
    "     circ_16])\n",
    "\n",
    "circs_combined = circs_combined.drop(['Unnamed: 8'],axis=1)\n",
    "combiner = circs_combined['catalogueRecordID'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurences = []\n",
    "\n",
    "for c in categs_combined['recId']:\n",
    "    #print(c)\n",
    "    try:\n",
    "        occurences.append(combiner[c])\n",
    "    except:\n",
    "        occurences.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "categs_combined['booking'] = occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educated-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "\n",
    "for y in categs_combined['yea']:\n",
    "    if y != 'Неизвестен':\n",
    "        new_y = y[0:3]\n",
    "        new_y = new_y + '0'\n",
    "    years.append(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "categs_combined['decade'] = years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_set = categs_combined[['aut','title','rubrics','decade','booking']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def clean_data(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\").replace(\":\", \"\").replace(\".\", \"\")) for i in x]\n",
    "    else:\n",
    "        #Check if director exists. If not, return empty string\n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\").replace(\":\", \"\").replace(\".\", \"\"))\n",
    "        else:\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['aut','title','rubrics','decade']\n",
    "\n",
    "for f in features:\n",
    "    needed_set[f] = needed_set[f].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_set = needed_set.replace(['неизвестно','неизвестен'],'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soup(x):\n",
    "    return ''.join(x['aut']) + ' ' + ''.join(x['title']) + ' ' + x['rubrics'] + ' ' + ''.join(x['decade'])\n",
    "\n",
    "needed_set['soup'] = needed_set.apply(create_soup, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "#needed_set = needed_set[:20000] # можно подкрутить или убрать ограничитель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(needed_set['soup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "count_matrix = count_matrix.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim2 = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(categs_combined.index, index=categs_combined['title']).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(user_id):\n",
    "    result_json = {}\n",
    "    history_set = circs_combined[circs_combined['readerID'] == user_id]\n",
    "    barcodes = history_set['barcode']\n",
    "    catalogue_info = {}\n",
    "    \n",
    "    for index, row in funds_combined.iterrows():\n",
    "        if row['barCode'] in list(barcodes):\n",
    "            catalogue_info[row['fundID']] = row['catalogueRecordID']\n",
    "    \n",
    "    res = dict((v,k) for k,v in catalogue_info.items())\n",
    "    \n",
    "    \n",
    "    list_of_history = []\n",
    "    list_of_recommendations = []\n",
    "    list_of_titles = []\n",
    "\n",
    "    for index, row in categs_combined.iterrows():\n",
    "        if row['recId'] in catalogue_info.values():\n",
    "            hist = {}\n",
    "            hist['id'] = res[row['recId']]\n",
    "            hist['title'] = row['title']\n",
    "            hist['author'] = row['aut']\n",
    "            \n",
    "            list_of_history.append(hist)\n",
    "            list_of_titles.append(row['title'])\n",
    "    \n",
    "    def get_recommendations(title, cosine_sim):\n",
    "        idx = indices[title]\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1]\n",
    "        book_indices = [i[0] for i in sim_scores]\n",
    "        return categs_combined[['recId','title','aut']].iloc[book_indices]\n",
    "    \n",
    "\n",
    "    recomms = []\n",
    "    \n",
    "    if len(list_of_titles) < 5:\n",
    "        if len(list_of_titles) == 0:\n",
    "            return \"Рекомендаций нет\"\n",
    "        else:\n",
    "            for l in list_of_titles:\n",
    "                result = get_recommendations(l,cosine_sim2).to_dict()\n",
    "                new_res = {}\n",
    "                for index, row in funds_combined.iterrows():\n",
    "                    if result['recId'] == row2['catalogueRecordID']:\n",
    "                        new_res['id'] = row2['catalogueRecordID']\n",
    "                        break\n",
    "                new_res['title'] = result['title']\n",
    "                new_res['author'] = result['aut']\n",
    "                recomms.append(new_res)\n",
    "    \n",
    "    result_json['recommendations'] = recomms\n",
    "    result_json['history'] = list_of_history\n",
    "    return result_json            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-crime",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-acceptance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-finance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
