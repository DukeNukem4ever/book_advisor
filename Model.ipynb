{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "metropolitan-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "romance-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_1 = pd.read_csv('cat_1.csv', sep=';',encoding='windows-1251')\n",
    "categ_2 = pd.read_csv('cat_2.csv', sep=';',encoding='windows-1251')\n",
    "categ_3 = pd.read_csv('cat_3.csv', sep=';',encoding='windows-1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "loaded-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "categs_combined = pd.concat([categ_1,categ_2,categ_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pretty-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "categs_combined['aut'] = categs_combined['aut'].fillna('Неизвестен')\n",
    "categs_combined['title'] = categs_combined['title'].fillna('Неизестно')\n",
    "categs_combined['place'] = categs_combined['place'].fillna('Неизестно')\n",
    "categs_combined['publ'] = categs_combined['publ'].fillna('Неизвестен')\n",
    "categs_combined['yea'] = categs_combined['yea'].fillna('Неизвестен')\n",
    "categs_combined['lan'] = categs_combined['lan'].fillna('Неизвестен')\n",
    "categs_combined['rubrics'] = categs_combined['rubrics'].fillna('Неизвестны')\n",
    "categs_combined['person'] = categs_combined['person'].fillna('Неизвестен')\n",
    "categs_combined['serial'] = categs_combined['serial'].fillna('Неизвестен')\n",
    "categs_combined['ager'] = categs_combined['ager'].fillna('Неизвестен')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "finnish-anime",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\artem\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3437: DtypeWarning: Columns (7,8,9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "c:\\users\\artem\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3437: DtypeWarning: Columns (7,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "fund_1 = pd.read_csv('fund_1.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_2 = pd.read_csv('fund_2.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_3 = pd.read_csv('fund_3.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_4 = pd.read_csv('fund_4.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_5 = pd.read_csv('fund_5.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_6 = pd.read_csv('fund_6.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_7 = pd.read_csv('fund_7.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_8 = pd.read_csv('fund_8.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_9 = pd.read_csv('fund_9.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_10 = pd.read_csv('fund_10_fix.csv', sep=';',encoding='windows-1251')\n",
    "fund_10 = fund_10.drop(['Unnamed: 8','Unnamed: 9'],axis=1)\n",
    "\n",
    "fund_11 = pd.read_csv('fund_11_fix.csv', sep=';',encoding='windows-1251')\n",
    "fund_11 = fund_11.drop(['Unnamed: 8','Unnamed: 9'],axis=1)\n",
    "\n",
    "fund_12 = pd.read_csv('fund_12_fix.csv', sep=';',encoding='windows-1251')\n",
    "fund_12 = fund_12.drop(['Unnamed: 8','Unnamed: 9'],axis=1)\n",
    "\n",
    "fund_13 = pd.read_csv('fund_13_fix.csv', sep=';',encoding='windows-1251')\n",
    "fund_13 = fund_13.drop(['Unnamed: 8','Unnamed: 9'],axis=1)\n",
    "\n",
    "fund_14 = pd.read_csv('fund_14.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_15 = pd.read_csv('fund_15.csv', sep=';',encoding='windows-1251')\n",
    "\n",
    "fund_16 = pd.read_csv('fund_16.csv', sep=';',encoding='windows-1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "editorial-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "funds_combined = pd.concat(\n",
    "    [fund_1,\n",
    "     fund_2,\n",
    "     fund_3,\n",
    "     fund_4,\n",
    "     fund_5,\n",
    "     fund_6,\n",
    "     fund_7,\n",
    "     fund_8,\n",
    "     fund_9,\n",
    "     fund_10,\n",
    "     fund_11,\n",
    "     fund_12,\n",
    "     fund_13,\n",
    "     fund_14,\n",
    "     fund_15,\n",
    "     fund_16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "operating-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "funds_combined = funds_combined.rename(columns={'Unnamed: 6':'siglaID_2',\n",
    "                               'Unnamed: 7':'inventoryNumber_2', \n",
    "                               'Unnamed: 8':'barCode_2',\n",
    "                               'Unnamed: 9':'trackIndex_2'})\n",
    "\n",
    "funds_combined['trackIndex'] = funds_combined['trackIndex'].fillna('Неизвестен')\n",
    "funds_combined['siglaID_2'] = funds_combined['siglaID_2'].fillna('Нет')\n",
    "funds_combined['inventoryNumber_2'] = funds_combined['inventoryNumber_2'].fillna('Нет')\n",
    "#funds_combined['barCode_2'] = funds_combined['barCode_2'].fillna('Нет')\n",
    "#funds_combined['trackIndex_2'] = funds_combined['trackIndex_2'].fillna('Нет')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "opening-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funds_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "impressive-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "circ_1 = pd.read_csv('circulaton_1.csv', sep=';',encoding='windows-1251')\n",
    "circ_2 = pd.read_csv('circulaton_2.csv', sep=';',encoding='windows-1251')\n",
    "circ_3 = pd.read_csv('circulaton_3.csv', sep=';',encoding='windows-1251')\n",
    "circ_4 = pd.read_csv('circulaton_4.csv', sep=';',encoding='windows-1251')\n",
    "circ_5 = pd.read_csv('circulaton_5.csv', sep=';',encoding='windows-1251')\n",
    "circ_6 = pd.read_csv('circulaton_6.csv', sep=';',encoding='windows-1251')\n",
    "circ_7 = pd.read_csv('circulaton_7.csv', sep=';',encoding='windows-1251')\n",
    "circ_8 = pd.read_csv('circulaton_8.csv', sep=';',encoding='windows-1251')\n",
    "circ_9 = pd.read_csv('circulaton_9.csv', sep=';',encoding='windows-1251')\n",
    "circ_10 = pd.read_csv('circulaton_10.csv', sep=';',encoding='windows-1251')\n",
    "circ_11 = pd.read_csv('circulaton_11.csv', sep=';',encoding='windows-1251')\n",
    "circ_12 = pd.read_csv('circulaton_12.csv', sep=';',encoding='windows-1251')\n",
    "circ_13 = pd.read_csv('circulaton_13.csv', sep=';',encoding='windows-1251')\n",
    "circ_14 = pd.read_csv('circulaton_14.csv', sep=';',encoding='windows-1251')\n",
    "circ_15 = pd.read_csv('circulaton_15.csv', sep=';',encoding='windows-1251')\n",
    "circ_16 = pd.read_csv('circulaton_16.csv', sep=';',encoding='windows-1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "infectious-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "circs_combined = pd.concat(\n",
    "    [circ_1,\n",
    "     circ_2,\n",
    "     circ_3,\n",
    "     circ_4,\n",
    "     circ_5,\n",
    "     circ_6,\n",
    "     circ_7,\n",
    "     circ_8,\n",
    "     circ_9,\n",
    "     circ_10,\n",
    "     circ_11,\n",
    "     circ_12,\n",
    "     circ_13,\n",
    "     circ_14,\n",
    "     circ_15,\n",
    "     circ_16])\n",
    "\n",
    "circs_combined = circs_combined.drop(['Unnamed: 8'],axis=1)\n",
    "combiner = circs_combined['catalogueRecordID'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "annoying-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurences = []\n",
    "\n",
    "for c in categs_combined['recId']:\n",
    "    #print(c)\n",
    "    try:\n",
    "        occurences.append(combiner[c])\n",
    "    except:\n",
    "        occurences.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "southern-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "categs_combined['booking'] = occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "educated-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "\n",
    "for y in categs_combined['yea']:\n",
    "    if y != 'Неизвестен':\n",
    "        new_y = y[0:3]\n",
    "        new_y = new_y + '0'\n",
    "    years.append(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eight-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "categs_combined['decade'] = years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hawaiian-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_set = categs_combined[['aut','title','rubrics','decade','booking']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "standing-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def clean_data(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\").replace(\":\", \"\").replace(\".\", \"\")) for i in x]\n",
    "    else:\n",
    "        #Check if director exists. If not, return empty string\n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\").replace(\":\", \"\").replace(\".\", \"\"))\n",
    "        else:\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "decent-palmer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-a4924916ac7f>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  needed_set[f] = needed_set[f].apply(clean_data)\n"
     ]
    }
   ],
   "source": [
    "features = ['aut','title','rubrics','decade']\n",
    "\n",
    "for f in features:\n",
    "    needed_set[f] = needed_set[f].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "taken-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_set = needed_set.replace(['неизвестно','неизвестен'],'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "concerned-poetry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soup(x):\n",
    "    return ''.join(x['aut']) + ' ' + ''.join(x['title']) + ' ' + x['rubrics'] + ' ' + ''.join(x['decade'])\n",
    "\n",
    "needed_set['soup'] = needed_set.apply(create_soup, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "initial-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "#needed_set = needed_set[:20000] # можно подкрутить или убрать ограничитель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "imported-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(needed_set['soup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "greek-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "count_matrix = count_matrix.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "middle-correlation",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 8.29 TiB for an array with shape (1139786590957,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8160ca43f37a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcosine_sim2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\artem\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1186\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m     K = safe_sparse_dot(X_normalized, Y_normalized.T,\n\u001b[0m\u001b[0;32m   1189\u001b[0m                         dense_output=dense_output)\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artem\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artem\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;32mc:\\users\\artem\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    558\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[0;32m    559\u001b[0m                              \"use '*' instead\")\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rmatmul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artem\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    478\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[1;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\artem\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmajor_axis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 8.29 TiB for an array with shape (1139786590957,) and data type int64"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim2 = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(categs_combined.index, index=categs_combined['title']).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(user_id):\n",
    "    result_json = {}\n",
    "    history_set = circs_combined[circs_combined['readerID'] == user_id]\n",
    "    barcodes = history_set['barcode']\n",
    "    catalogue_info = {}\n",
    "    \n",
    "    for index, row in funds_combined.iterrows():\n",
    "        if row['barCode'] in list(barcodes):\n",
    "            catalogue_info[row['fundID']] = row['catalogueRecordID']\n",
    "    \n",
    "    res = dict((v,k) for k,v in catalogue_info.items())\n",
    "    \n",
    "    \n",
    "    list_of_history = []\n",
    "    list_of_recommendations = []\n",
    "    list_of_titles = []\n",
    "\n",
    "    for index, row in categs_combined.iterrows():\n",
    "        if row['recId'] in catalogue_info.values():\n",
    "            hist = {}\n",
    "            hist['id'] = res[row['recId']]\n",
    "            hist['title'] = row['title']\n",
    "            hist['author'] = row['aut']\n",
    "            \n",
    "            list_of_history.append(hist)\n",
    "            list_of_titles.append(row['title'])\n",
    "    \n",
    "    def get_recommendations(title, cosine_sim):\n",
    "        idx = indices[title]\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_scores = sim_scores[1]\n",
    "        book_indices = [i[0] for i in sim_scores]\n",
    "        return categs_combined[['recId','title','aut']].iloc[book_indices]\n",
    "    \n",
    "\n",
    "    recomms = []\n",
    "    \n",
    "    if len(list_of_titles) < 5:\n",
    "        if len(list_of_titles) == 0:\n",
    "            return \"Рекомендаций нет\"\n",
    "        else:\n",
    "            for l in list_of_titles:\n",
    "                result = get_recommendations(l,cosine_sim2).to_dict()\n",
    "                new_res = {}\n",
    "                for index, row in funds_combined.iterrows():\n",
    "                    if result['recId'] == row2['catalogueRecordID']:\n",
    "                        new_res['id'] = row2['catalogueRecordID']\n",
    "                        break\n",
    "                new_res['title'] = result['title']\n",
    "                new_res['author'] = result['aut']\n",
    "                recomms.append(new_res)\n",
    "    \n",
    "    result_json['recommendations'] = recomms\n",
    "    result_json['history'] = list_of_history\n",
    "    return result_json            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "overhead-tyler",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recommendations': [],\n",
       " 'history': [{'id': 75667, 'title': 'Семья 3х1', 'author': 'Майорош Нора'},\n",
       "  {'id': 130425,\n",
       "   'title': 'Карлсон, который живет на крыше, проказничает опять',\n",
       "   'author': 'Линдгрен Астрид'},\n",
       "  {'id': 130486,\n",
       "   'title': 'Карлсон, который живет на крыше, опять прилетел',\n",
       "   'author': 'Линдгрен Астрид'},\n",
       "  {'id': 154119,\n",
       "   'title': 'Чей нос лучше?',\n",
       "   'author': 'Бианки Виталий Валентинович'},\n",
       "  {'id': 198213,\n",
       "   'title': 'Карлссон, который живет на крыше',\n",
       "   'author': 'Линдгрен Астрид'},\n",
       "  {'id': 8832196, 'title': 'Кусака', 'author': 'Андреев Леонид'},\n",
       "  {'id': 6864267, 'title': 'Ю-Ю', 'author': 'Куприн Александр Иванович'},\n",
       "  {'id': 11022962, 'title': 'Мальчики', 'author': 'Чехов Антон Павлович'},\n",
       "  {'id': 10613312,\n",
       "   'title': 'Стрижонок Скрип',\n",
       "   'author': 'Астафьев Виктор Петрович'},\n",
       "  {'id': 1441407,\n",
       "   'title': 'Приемыш',\n",
       "   'author': 'Мамин-Сибиряк Дмитрий Наркисович'},\n",
       "  {'id': 425815,\n",
       "   'title': 'Неизвестный цветок',\n",
       "   'author': 'Платонов Андрей Платонович'},\n",
       "  {'id': 672147,\n",
       "   'title': 'Приключения Незнайки и его друзей , Незнайка в Солнечном городе , Незнайка на Луне',\n",
       "   'author': 'Носов Николай Николаевич'},\n",
       "  {'id': 366430,\n",
       "   'title': 'Этажи леса',\n",
       "   'author': 'Пришвин Михаил Михайлович'}]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(1188)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-diploma",
   "metadata": {},
   "outputs": [],
   "source": [
    "search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-queue",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-platform",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "academic-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_recommendations(title, cosine_sim):\n",
    "#    idx = indices[title]\n",
    "\n",
    "#    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "#    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#    sim_scores = sim_scores[1:11]\n",
    "\n",
    "#    book_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "#    return categs_combined[['title','aut','yea','rubrics']].iloc[book_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "worse-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def user_search(user_id):\n",
    "#    #result_json = {\"recommendations\":[],\n",
    "#    #              \"history\":[]}\n",
    "#    result_json = {}\n",
    "#    history_set = circs_combined[circs_combined['readerID'] == user_id]\n",
    "#    \n",
    "#    barcodes = history_set['barcode']\n",
    "#    #print(list(barcodes))\n",
    "#    catalogue_info = {}\n",
    "#    \n",
    "#    for index, row in funds_combined.iterrows():\n",
    "#        #print(row['barCode'])\n",
    "#        #print(row['barCode'])\n",
    "#        if row['barCode'] in list(barcodes):\n",
    "#            catalogue_info[row['fundID']] = row['catalogueRecordID']\n",
    "#            #catalogue_id.append()\n",
    "#            #catalogue_recs.append()\n",
    "    \n",
    "#    res = dict((v,k) for k,v in catalogue_info.items())\n",
    "    \n",
    "    \n",
    "#    list_of_history = []\n",
    "#    list_of_recommendations = []\n",
    "#    #list_of_recs = []\n",
    "#    list_of_authors = []\n",
    "#    #list_of_ratings = []\n",
    "#    list_of_years = []\n",
    "#    list_of_rubrics = []\n",
    "#    \n",
    "#    for index, row in categs_combined.iterrows():\n",
    "#        if row['recId'] in catalogue_info.values():\n",
    "#            hist = {}\n",
    "#            hist['id'] = res[row['recId']]\n",
    "#            hist['title'] = row['title']\n",
    "#            hist['author'] = row['aut']\n",
    "#            #hist['rubrics'] = row['rubrics']\n",
    "#            \n",
    "#            list_of_history.append(hist)\n",
    "#    \n",
    "#            #sim_scores = list(enumerate(cosine_sim[row['recId']]))\n",
    "#    \n",
    "#            list_of_authors.append(row['aut'])\n",
    "#            #list_of_ratings.append(row['aut'])\n",
    "#            list_of_years.append(row['yea'])\n",
    "#            list_of_rubrics.append(row['rubrics'])\n",
    "#    \n",
    "    \n",
    "#    \n",
    "#    new_cats = shuffle(categs_combined)\n",
    "#    \n",
    "#    #recom_info = {}\n",
    "#    \n",
    "#    i = 0\n",
    "#    for index, row in new_cats.iterrows():\n",
    "#        #if '' not in row.values():\n",
    "#        #if row['rubrics'] in list_of_rubrics or row['aut'] in list_of_authors or row['yea'] in list_of_years:\n",
    "#        if i < 5:\n",
    "#            if row['rubrics'] in list_of_rubrics and row['aut'] in list_of_authors:# and 'Неизвестен' not in row.values() and 'Неизестно' not in row.values():\n",
    "#                if row['aut'] != 'Неизвестен' and row['title'] != 'Неизвестно':\n",
    "#                    recs = {}\n",
    "#                    recs2 = {}\n",
    "#                \n",
    "#                    for index2, row2 in funds_combined.iterrows():\n",
    "#                        if row['recId'] == row2['catalogueRecordID']:\n",
    "#                            recs['id'] = row2['catalogueRecordID']\n",
    "#                            break\n",
    "#                    #if row['recId'] in fun       \n",
    "#                    #recs['id'] = row['recId']\n",
    "#                    recs['title'] = row['title']\n",
    "#                    recs['author'] = row['aut']\n",
    "#                    #recs['rubrics'] = row['rubrics']\n",
    "#                    list_of_recommendations.append(recs)\n",
    "#                    i += 1\n",
    "#        else:\n",
    "#            break\n",
    "    \n",
    "#    result_json['recommendations'] = list_of_recommendations[0:5]\n",
    "#    result_json['history'] = list_of_history\n",
    "    \n",
    "#    print()\n",
    "    #print(list_of_recommendations)\n",
    "#    return result_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-finance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
